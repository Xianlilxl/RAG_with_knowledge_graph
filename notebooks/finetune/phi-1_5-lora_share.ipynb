{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from peft import LoraConfig\n",
    "\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Babelscape/REDFM\", language='all_languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset['train']\n",
    "# dir(train_ds)\n",
    "fr_train_ds = train_ds.filter(lambda example: example['lan'] == 'fr')\n",
    "example = fr_train_ds[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1865"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subject': {'uri': 'Q2277',\n",
       "   'surfaceform': 'impérial',\n",
       "   'type': 'LOC',\n",
       "   'start': 53,\n",
       "   'end': 61},\n",
       "  'predicate': 22,\n",
       "  'object': {'uri': 'Q1747689',\n",
       "   'surfaceform': 'Rome antique',\n",
       "   'type': 'LOC',\n",
       "   'start': 68,\n",
       "   'end': 80}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"relations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La Domus aurea ou Maison dorée est un immense palais impérial de la Rome antique, construit pour Néron, qui couvrait une partie importante de Rome \"intra muros\" sur plusieurs dizaines d\\'hectares. Elle doit son nom aux feuilles d\\'or destinées à rehausser certains motifs du décor des fresques. Elle comportait plusieurs bâtiments distincts, de vastes jardins, un lac artificiel, mais aussi une salle de banquet qui tournait sur elle-même. Après la mort de Néron, l\\'espace occupé fut rendu aux Romains et le Colisée fut édifié sur l\\'emplacement du lac asséché. Ensevelie pendant des siècles, la \"Domus aurea\" fut en partie redécouverte à la Renaissance.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domus aurea\n",
      "impérial\n",
      "Rome antique\n",
      "Néron\n",
      "Rome\n",
      "intra muros\n",
      "Colisée\n",
      "Domus aurea\n",
      "Renaissance\n"
     ]
    }
   ],
   "source": [
    "for entity in example['entities']:\n",
    "    print(entity['surfaceform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1865"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELATION_NAMES=['pays', 'lieu de naissance', 'conjoint', 'pays de nationalité', 'instance de',\n",
    "#         'capital', 'enfant', 'partage la frontière avec', 'auteur', 'directeur', 'occupation',\n",
    "#           'fondée par', 'ligue', 'appartenant à', 'genre', 'nommé d\\'après', 'suit',\n",
    "#             'localisation du siège social', 'membre du casting', 'constructeur',\n",
    "#               'situé dans ou à côté d\\'une étendue d\\'eau', 'localisation', 'partie de', \n",
    "#               'embouchure du cours d\\'eau', 'membre de', 'sport', 'caractères',\n",
    "#                 'participant', 'travail remarquable', 'remplacer', 'frère et sœur', 'création']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(example):\n",
    "\n",
    "    RELATION_NAMES=['country', 'place of birth', 'spouse', 'country of citizenship', 'instance of',\n",
    "            'capital', 'child', 'shares border with', 'author', 'director', 'occupation',\n",
    "              'founded by', 'league', 'owned by', 'genre', 'named after', 'follows',\n",
    "                'headquarters location', 'cast member', 'manufacturer',\n",
    "                  'located in or next to body of water', 'location', 'part of', \n",
    "                  'mouth of the watercourse', 'member of', 'sport', 'characters',\n",
    "                    'participant', 'notable work', 'replaces', 'sibling', 'inception']\n",
    "    relations = []\n",
    "    for relation in example['relations']:\n",
    "        object = relation['object']['surfaceform']\n",
    "        subject = relation['subject']['surfaceform']\n",
    "        predicate = RELATION_NAMES[relation['predicate']]\n",
    "        relations.append(f\"[’{subject}’, ’{predicate}’, ’{object}’]\")\n",
    "\n",
    " \n",
    "    return ' | '.join(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[’impérial’, ’partie de’, ’Rome antique’]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations = get_relation(example)\n",
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Vous êtes un expert en data science et en traitement du langage naturel(NLP).\n",
       "Votre tâche consiste à extraire les triplets du TEXTE fourni ci-dessous.\n",
       "Un triplet de connaissances est constitué de 2 entités (sujet et objet) liées par un prédicat : \n",
       "['sujet', 'prédicat', 'objet'].\n",
       "Les triples multiples doivent être séparés par ' | '.\n",
       "\n",
       "TEXTE: La Domus aurea ou Maison dorée est un immense palais impérial de la Rome antique, construit pour Néron, qui couvrait une partie importante de Rome \"intra muros\" sur plusieurs dizaines d'hectares. Elle doit son nom aux feuilles d'or destinées à rehausser certains motifs du décor des fresques. Elle comportait plusieurs bâtiments distincts, de vastes jardins, un lac artificiel, mais aussi une salle de banquet qui tournait sur elle-même. Après la mort de Néron, l'espace occupé fut rendu aux Romains et le Colisée fut édifié sur l'emplacement du lac asséché. Ensevelie pendant des siècles, la \"Domus aurea\" fut en partie redécouverte à la Renaissance.\n",
       "\n",
       "Relations: [’impérial’, ’partie de’, ’Rome antique’]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "rel_template = \"\"\"Vous êtes un expert en data science et en traitement du langage naturel(NLP).\n",
    "Votre tâche consiste à extraire les triplets du TEXTE fourni ci-dessous.\n",
    "Un triplet de connaissances est constitué de 2 entités (sujet et objet) liées par un prédicat : \n",
    "['sujet', 'prédicat', 'objet'].\n",
    "Les triples multiples doivent être séparés par ' | '.\\n\n",
    "TEXTE: {text}\\n\n",
    "Relations: {answer}\"\"\"\n",
    "\n",
    "rel_prompt = PromptTemplate(template=rel_template, input_variables=['text', 'answer'])\n",
    "\n",
    "display(Markdown(rel_prompt.format(text=example['text'], \n",
    "                               answer=get_relation(example))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output = []\n",
    "for entry in fr_train_ds:\n",
    "    output.append({\"instruction\": \"\"\"Vous êtes un expert en data science et en traitement du langage naturel(NLP). Votre tâche consiste à extraire les triplets du TEXTE fourni ci-dessous. Un triplet de connaissances est constitué de 2 entités (sujet et objet) liées par un prédicat : ['sujet', 'prédicat', 'objet']. Les triples multiples doivent être séparés par ' | '.\\n\"\"\",\n",
    "                    \"input\": entry['text'],\n",
    "                    \"output\": get_relation(entry)})\n",
    "# Serializing json\n",
    "# json_object = json.dumps(output, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"../../data/REDFM_fr.json\", \"w\") as outfile:\n",
    "    # outfile.write(json_object)\n",
    "    json.dump(output, outfile, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1865"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(example):\n",
    "    text = rel_prompt.format(\n",
    "        text=example['text'], \n",
    "        answer=get_relation(example))\n",
    "    return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['docid', 'title', 'uri', 'lan', 'text', 'entities', 'relations'],\n",
       "    num_rows: 1865\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fr_train_ds.map(format_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid': '4927370-0',\n",
       " 'title': 'Chypre du Nord',\n",
       " 'uri': 'Q23681',\n",
       " 'lan': 'fr',\n",
       " 'text': \"Vous êtes un expert en data science et en traitement du langage naturel(NLP).\\nVotre tâche consiste à extraire les triplets du TEXTE fourni ci-dessous.\\nUn triplet de connaissances est constitué de 2 entités (sujet et objet) liées par un prédicat : \\n['sujet', 'prédicat', 'objet'].\\nLes triples multiples doivent être séparés par ' | '.\\n\\nTEXTE: Chypre du Nord et, en forme longue, la république turque de Chypre du Nord (dénomination abrégée en RTCN), en turc (abrégé en ou en ), est un État reconnu uniquement par la Turquie et, un temps, par le Pakistan, situé dans la partie nord-est de l'île de Chypre. Elle a proclamé son indépendance le , neuf ans après l'intervention militaire turque de 1974, alors en réaction à la tentative de rattachement de l'île à la Grèce par un groupe d'officiers putschistes de la garde nationale chypriote (l'EOKA B) mené par Níkos Sampsón après le renversement du président .\\n\\nRelations: [’Chypre du Nord’, ’localisation’, ’île de Chypre’] | [’turc’, ’pays’, ’Chypre du Nord’] | [’île de Chypre’, ’pays’, ’Chypre du Nord’]\",\n",
       " 'entities': [{'uri': 'Q23681',\n",
       "   'surfaceform': 'Chypre du Nord',\n",
       "   'type': 'ORG',\n",
       "   'start': 0,\n",
       "   'end': 14},\n",
       "  {'uri': 'Q23681',\n",
       "   'surfaceform': 'Chypre du Nord',\n",
       "   'type': 'ORG',\n",
       "   'start': 60,\n",
       "   'end': 74},\n",
       "  {'uri': 'Q256',\n",
       "   'surfaceform': 'turc',\n",
       "   'type': 'Concept',\n",
       "   'start': 110,\n",
       "   'end': 114},\n",
       "  {'uri': 'Q199683',\n",
       "   'surfaceform': 'État reconnu uniquement',\n",
       "   'type': 'Concept',\n",
       "   'start': 142,\n",
       "   'end': 165},\n",
       "  {'uri': 'Q43',\n",
       "   'surfaceform': 'Turquie',\n",
       "   'type': 'LOC',\n",
       "   'start': 173,\n",
       "   'end': 180},\n",
       "  {'uri': 'Q644636',\n",
       "   'surfaceform': 'île de Chypre',\n",
       "   'type': 'LOC',\n",
       "   'start': 247,\n",
       "   'end': 260},\n",
       "  {'uri': 'Q1050999',\n",
       "   'surfaceform': \"l'intervention militaire turque\",\n",
       "   'type': 'EVE',\n",
       "   'start': 315,\n",
       "   'end': 346},\n",
       "  {'uri': 'Q2478',\n",
       "   'surfaceform': '1974',\n",
       "   'type': 'TIME',\n",
       "   'start': 350,\n",
       "   'end': 354},\n",
       "  {'uri': '+1974^^http://www.w3.org/2001/XMLSchema#decimal',\n",
       "   'surfaceform': '1974',\n",
       "   'type': 'NUMBER',\n",
       "   'start': 350,\n",
       "   'end': 354},\n",
       "  {'uri': 'Q41',\n",
       "   'surfaceform': 'Grèce',\n",
       "   'type': 'LOC',\n",
       "   'start': 419,\n",
       "   'end': 424},\n",
       "  {'uri': 'Q2700279',\n",
       "   'surfaceform': 'EOKA B',\n",
       "   'type': 'ORG',\n",
       "   'start': 498,\n",
       "   'end': 504},\n",
       "  {'uri': 'Q552189',\n",
       "   'surfaceform': 'Níkos Sampsón',\n",
       "   'type': 'PER',\n",
       "   'start': 515,\n",
       "   'end': 528},\n",
       "  {'uri': 'Q2069434',\n",
       "   'surfaceform': 'renversement du président',\n",
       "   'type': 'Concept',\n",
       "   'start': 538,\n",
       "   'end': 563}],\n",
       " 'relations': [{'subject': {'uri': 'Q23681',\n",
       "    'surfaceform': 'Chypre du Nord',\n",
       "    'type': 'ORG',\n",
       "    'start': 0,\n",
       "    'end': 14},\n",
       "   'predicate': 21,\n",
       "   'object': {'uri': 'Q644636',\n",
       "    'surfaceform': 'île de Chypre',\n",
       "    'type': 'LOC',\n",
       "    'start': 247,\n",
       "    'end': 260}},\n",
       "  {'subject': {'uri': 'Q256',\n",
       "    'surfaceform': 'turc',\n",
       "    'type': 'Concept',\n",
       "    'start': 110,\n",
       "    'end': 114},\n",
       "   'predicate': 0,\n",
       "   'object': {'uri': 'Q23681',\n",
       "    'surfaceform': 'Chypre du Nord',\n",
       "    'type': 'ORG',\n",
       "    'start': 0,\n",
       "    'end': 14}},\n",
       "  {'subject': {'uri': 'Q644636',\n",
       "    'surfaceform': 'île de Chypre',\n",
       "    'type': 'LOC',\n",
       "    'start': 247,\n",
       "    'end': 260},\n",
       "   'predicate': 0,\n",
       "   'object': {'uri': 'Q23681',\n",
       "    'surfaceform': 'Chypre du Nord',\n",
       "    'type': 'ORG',\n",
       "    'start': 0,\n",
       "    'end': 14}}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence_lengths(data, split='train', max_length=2048):\n",
    "    sequence_lengths = []\n",
    "    keep_indices = []\n",
    "\n",
    "    # Loop over the dataset and get the lengths of text sequences\n",
    "    # for i, example in enumerate(data[split]):\n",
    "    for i, example in enumerate(data):\n",
    "        sequence_lengths.append(len(example['text']))\n",
    "        if sequence_lengths[i] < max_length:\n",
    "            keep_indices.append(i)\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.hist(sequence_lengths, bins=30)\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Text Sequence Lengths')\n",
    "    plt.show()\n",
    "\n",
    "    return keep_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_indices_train = plot_sequence_lengths(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select(keep_indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"bofenghuang/vigo-mistral-7b-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    # target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n",
    "    target_modules=[\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    # load_in_8bit=True,\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shitty hack\n",
    "# TODO get the new mixformer class from huggingface, it works with \"gradient_checkpointing_enable\"\n",
    "def gradient_checkpointing_enable():\n",
    "    pass\n",
    "\n",
    "base_model.gradient_checkpointing_enable = gradient_checkpointing_enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./SFT-phi-1p5b\", \n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    max_steps=4000,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    fp16=True,\n",
    "    run_name=\"baseline-phi-sft\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid': '4927370-0',\n",
       " 'title': 'Chypre du Nord',\n",
       " 'uri': 'Q23681',\n",
       " 'lan': 'fr',\n",
       " 'text': \"Vous êtes un expert en data science et en traitement du langage naturel(NLP).\\nVotre tâche consiste à extraire les triplets du TEXTE fourni ci-dessous.\\nUn triplet de connaissances est constitué de 2 entités (sujet et objet) liées par un prédicat : \\n['sujet', 'prédicat', 'objet'].\\nLes triples multiples doivent être séparés par ' | '.\\n\\nTEXTE: Chypre du Nord et, en forme longue, la république turque de Chypre du Nord (dénomination abrégée en RTCN), en turc (abrégé en ou en ), est un État reconnu uniquement par la Turquie et, un temps, par le Pakistan, situé dans la partie nord-est de l'île de Chypre. Elle a proclamé son indépendance le , neuf ans après l'intervention militaire turque de 1974, alors en réaction à la tentative de rattachement de l'île à la Grèce par un groupe d'officiers putschistes de la garde nationale chypriote (l'EOKA B) mené par Níkos Sampsón après le renversement du président .\\n\\nRelations: [’Chypre du Nord’, ’localisation’, ’île de Chypre’] | [’turc’, ’pays’, ’Chypre du Nord’] | [’île de Chypre’, ’pays’, ’Chypre du Nord’]\",\n",
       " 'entities': [{'uri': 'Q23681',\n",
       "   'surfaceform': 'Chypre du Nord',\n",
       "   'type': 'ORG',\n",
       "   'start': 0,\n",
       "   'end': 14},\n",
       "  {'uri': 'Q23681',\n",
       "   'surfaceform': 'Chypre du Nord',\n",
       "   'type': 'ORG',\n",
       "   'start': 60,\n",
       "   'end': 74},\n",
       "  {'uri': 'Q256',\n",
       "   'surfaceform': 'turc',\n",
       "   'type': 'Concept',\n",
       "   'start': 110,\n",
       "   'end': 114},\n",
       "  {'uri': 'Q199683',\n",
       "   'surfaceform': 'État reconnu uniquement',\n",
       "   'type': 'Concept',\n",
       "   'start': 142,\n",
       "   'end': 165},\n",
       "  {'uri': 'Q43',\n",
       "   'surfaceform': 'Turquie',\n",
       "   'type': 'LOC',\n",
       "   'start': 173,\n",
       "   'end': 180},\n",
       "  {'uri': 'Q644636',\n",
       "   'surfaceform': 'île de Chypre',\n",
       "   'type': 'LOC',\n",
       "   'start': 247,\n",
       "   'end': 260},\n",
       "  {'uri': 'Q1050999',\n",
       "   'surfaceform': \"l'intervention militaire turque\",\n",
       "   'type': 'EVE',\n",
       "   'start': 315,\n",
       "   'end': 346},\n",
       "  {'uri': 'Q2478',\n",
       "   'surfaceform': '1974',\n",
       "   'type': 'TIME',\n",
       "   'start': 350,\n",
       "   'end': 354},\n",
       "  {'uri': '+1974^^http://www.w3.org/2001/XMLSchema#decimal',\n",
       "   'surfaceform': '1974',\n",
       "   'type': 'NUMBER',\n",
       "   'start': 350,\n",
       "   'end': 354},\n",
       "  {'uri': 'Q41',\n",
       "   'surfaceform': 'Grèce',\n",
       "   'type': 'LOC',\n",
       "   'start': 419,\n",
       "   'end': 424},\n",
       "  {'uri': 'Q2700279',\n",
       "   'surfaceform': 'EOKA B',\n",
       "   'type': 'ORG',\n",
       "   'start': 498,\n",
       "   'end': 504},\n",
       "  {'uri': 'Q552189',\n",
       "   'surfaceform': 'Níkos Sampsón',\n",
       "   'type': 'PER',\n",
       "   'start': 515,\n",
       "   'end': 528},\n",
       "  {'uri': 'Q2069434',\n",
       "   'surfaceform': 'renversement du président',\n",
       "   'type': 'Concept',\n",
       "   'start': 538,\n",
       "   'end': 563}],\n",
       " 'relations': [{'subject': {'uri': 'Q23681',\n",
       "    'surfaceform': 'Chypre du Nord',\n",
       "    'type': 'ORG',\n",
       "    'start': 0,\n",
       "    'end': 14},\n",
       "   'predicate': 21,\n",
       "   'object': {'uri': 'Q644636',\n",
       "    'surfaceform': 'île de Chypre',\n",
       "    'type': 'LOC',\n",
       "    'start': 247,\n",
       "    'end': 260}},\n",
       "  {'subject': {'uri': 'Q256',\n",
       "    'surfaceform': 'turc',\n",
       "    'type': 'Concept',\n",
       "    'start': 110,\n",
       "    'end': 114},\n",
       "   'predicate': 0,\n",
       "   'object': {'uri': 'Q23681',\n",
       "    'surfaceform': 'Chypre du Nord',\n",
       "    'type': 'ORG',\n",
       "    'start': 0,\n",
       "    'end': 14}},\n",
       "  {'subject': {'uri': 'Q644636',\n",
       "    'surfaceform': 'île de Chypre',\n",
       "    'type': 'LOC',\n",
       "    'start': 247,\n",
       "    'end': 260},\n",
       "   'predicate': 0,\n",
       "   'object': {'uri': 'Q23681',\n",
       "    'surfaceform': 'Chypre du Nord',\n",
       "    'type': 'ORG',\n",
       "    'start': 0,\n",
       "    'end': 14}}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kkondratenko/python_envs/P310_general/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "Loading cached processed dataset at /home/kkondratenko/.cache/huggingface/datasets/Babelscape___redfm/default-language=all_languages/1.0.0/576b7e6025452757ea5242348575c40d8d8c8d333b50445bc5909cde4bd903ee/cache-7600d89f7148dec0.arrow\n"
     ]
    }
   ],
   "source": [
    "supervised_finetuning_trainer = SFTTrainer(\n",
    "    base_model,\n",
    "    # train_dataset=data[\"train\"],\n",
    "    train_dataset=data,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=qlora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    data_collator=DataCollatorForCompletionOnlyLM(tokenizer=tokenizer, \n",
    "                                                  response_template=\"Relations:\")\n",
    "                                                #   response_template=\"Answer:\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kkondratenko/dev_scripts/NLP/KG/wandb/run-20230919_142649-pvfh68bd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kkn_420/phi-re_finetune/runs/pvfh68bd' target=\"_blank\">baseline-phi-sft</a></strong> to <a href='https://wandb.ai/kkn_420/phi-re_finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kkn_420/phi-re_finetune' target=\"_blank\">https://wandb.ai/kkn_420/phi-re_finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kkn_420/phi-re_finetune/runs/pvfh68bd' target=\"_blank\">https://wandb.ai/kkn_420/phi-re_finetune/runs/pvfh68bd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/4000 00:00 < 40:41, 1.64 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=0.1438879871368408, metrics={'train_runtime': 9452.9583, 'train_samples_per_second': 0.846, 'train_steps_per_second': 0.423, 'total_flos': 8837084005146624.0, 'train_loss': 0.1438879871368408, 'epoch': 2.79})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_finetuning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_finetuning_trainer.save_model('./adapter_phi_re')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    # load_in_4bit=True,\n",
    "    # quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")#.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import PeftConfig\n",
    "\n",
    "adapter_model_id = \"./adapter_phi_re\"\n",
    "# peft_config = PeftConfig.from_pretrained(adapter_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel \n",
    "\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapter_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline_peft = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            # torch_dtype=torch.bfloat16,\n",
    "            # generation_config=gen_cfg,\n",
    "            temperature=0.0001,\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\",\n",
    "            return_full_text=False,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an AI expert in data science and natural language processing.\\nYour task is to extract the knowledge triplets from the TEXT provided below.\\nA knowledge triplet consists of 2 entities (subject and object) linked by a predicate: \\n[’subject’, ’predicate’, ’object’].\\nMultiple triples must be separated with \\' | \\'\\n\\nTEXT: La Domus aurea ou Maison dorée est un immense palais impérial de la Rome antique, construit pour Néron, qui couvrait une partie importante de Rome \"intra muros\" sur plusieurs dizaines d\\'hectares. Elle doit son nom aux feuilles d\\'or destinées à rehausser certains motifs du décor des fresques. Elle comportait plusieurs bâtiments distincts, de vastes jardins, un lac artificiel, mais aussi une salle de banquet qui tournait sur elle-même. Après la mort de Néron, l\\'espace occupé fut rendu aux Romains et le Colisée fut édifié sur l\\'emplacement du lac asséché. Ensevelie pendant des siècles, la \"Domus aurea\" fut en partie redécouverte à la Renaissance.\\n\\nRelations: [’impérial’, ’part of’, ’Rome antique’]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_prompt.format(text=example['text'], \n",
    "                               answer=get_relation(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proompt = rel_prompt.format(text=example['text'], \n",
    "#                                answer=\"\")\n",
    "# proompt = rel_prompt.format(text=\"Philz is a coffee shop founded in Berkeley in 1982.\", \n",
    "#                                answer=\"\")\n",
    "proompt = rel_prompt.format(text=\"In the bustling streets of the ancient city, the skilled blacksmith crafted a magnificent sword, which soon became the talk of the town.\", \n",
    "                               answer=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_peft(proompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "def generate_text(query):\n",
    "    gen_cfg = GenerationConfig.from_model_config(model.config)\n",
    "    # gen_cfg.max_new_tokens = DEFAULT_MAX_LENGTH\n",
    "    # gen_cfg.temperature = 0.51\n",
    "    gen_cfg.num_return_sequences = 1\n",
    "    gen_cfg.use_cache = True\n",
    "    gen_cfg.min_length = 1\n",
    "\n",
    "    inputs = tokenizer(query, \n",
    "                       return_tensors=\"pt\", \n",
    "                       return_attention_mask=False)#.to('cuda')\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512, \n",
    "        generation_config=gen_cfg,\n",
    "        do_sample=True, \n",
    "        temperature=0.01, \n",
    "        top_p=0.9, \n",
    "        # use_cache=True, \n",
    "        repetition_penalty=1.2, \n",
    "        eos_token_id=tokenizer.eos_token_id)\n",
    "    text = tokenizer.batch_decode(outputs)[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI expert in data science and natural language processing.\n",
      "Your task is to extract the knowledge triplets from the TEXT provided below.\n",
      "A knowledge triplet consists of 2 entities (subject and object) linked by a predicate: \n",
      "[’subject’, ’predicate’, ’object’].\n",
      "Multiple triples must be separated with'| '\n",
      "\n",
      "TEXT: In the bustling streets of the ancient city, the skilled blacksmith crafted a magnificent sword, which soon became the talk of the town.\n",
      "\n",
      "Relations: \n",
      "- Subject : The blacksmith\n",
      "  Predicate : Crafted a majestic sword\n",
      "  Object : A magnificent weapon that captivated everyone's attention\n",
      "\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "resp = generate_text(proompt)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
