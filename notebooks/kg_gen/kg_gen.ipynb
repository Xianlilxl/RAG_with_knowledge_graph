{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccd9b35",
   "metadata": {},
   "source": [
    "# KG generation with customized LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1469e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from transformers import BitsAndBytesConfig\n",
    "from IPython.display import Markdown, display\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from typing import Optional, List, Mapping, Any, Tuple\n",
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "from llama_index import (\n",
    "    ServiceContext, \n",
    "    SimpleDirectoryReader, \n",
    "#     LangchainEmbedding, \n",
    "#     ListIndex,\n",
    "    KnowledgeGraphIndex\n",
    ")\n",
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.llms import (\n",
    "    CustomLLM, \n",
    "    CompletionResponse, \n",
    "    CompletionResponseGen,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "from llama_index.llms.base import llm_completion_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567bc36b",
   "metadata": {},
   "source": [
    "### 4bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135a1964",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36db233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb47ce10a263413ab4fb714dd073d631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c54e2e152441edba3fbbdd2ff6c029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acfca3766334bdf8d927c90f40cc735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ba96db3f774016958fed4a508efae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/miniconda3/envs/llm_venv/lib/python3.10/site-packages/bitsandbytes-0.41.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:106: UserWarning: \n",
      "\n",
      "================================================================================\n",
      "WARNING: Manual override via BNB_CUDA_VERSION env variable detected!\n",
      "BNB_CUDA_VERSION=XXX can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "Loading CUDA version: BNB_CUDA_VERSION=116\n",
      "================================================================================\n",
      "\n",
      "\n",
      "  warn((f'\\n\\n{\"=\"*80}\\n'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966b5a2addd14bd08a1255514c7e5417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2c5b1f127141318448f61cb253a039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set context window size\n",
    "context_window = 2048\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "\n",
    "# model_name = \"bofenghuang/vigostral-7b-chat\"\n",
    "# model_name = \"Open-Orca/Mistral-7B-OpenOrca\"\n",
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, device_map=\"auto\", quantization_config=quantization_config, trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665ab23",
   "metadata": {},
   "source": [
    "### Config the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3caf1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88af5a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_KG_TRIPLET_EXTRACT_TMPL = (\n",
    "    \"Some text is provided below. Given the text, extract up to \"\n",
    "    \"{max_knowledge_triplets} \"\n",
    "    \"knowledge triplets in the form of (subject, predicate, object). Avoid stopwords.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Example:\"\n",
    "    \"Text: Alice is Bob's mother.\"\n",
    "    \"Triplets:\\n(Alice, is mother of, Bob)\\n\"\n",
    "    \"Text: Philz is a coffee shop founded in Berkeley in 1982.\\n\"\n",
    "    \"Triplets:\\n\"\n",
    "    \"(Philz, is, coffee shop)\\n\"\n",
    "    \"(Philz, founded in, Berkeley)\\n\"\n",
    "    \"(Philz, founded in, 1982)\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Text: {text}\\n\"\n",
    "    \"Triplets:\\n\"\n",
    ")\n",
    "encoded = tokenizer.encode(\"Les chercheurs ont découvert une nouvelle espèce de papillon, qui vit exclusivement dans les forêts tropicales humides.\")\n",
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4808e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"La découverte de la pénicilline par Alexander Fleming en 1928 a révolutionné le domaine médical. Cette avancée majeure a ouvert la voie à la fabrication d'antibiotiques, qui ont depuis sauvé d'innombrables vies. La pénicilline, un antibiotique naturel produit par le champignon Penicillium, a démontré son efficacité dans le traitement des infections bactériennes. La capacité de la pénicilline à tuer les bactéries a été le sujet de nombreuses études scientifiques. Ces recherches ont permis de comprendre comment la pénicilline agit en inhibant la synthèse de la paroi cellulaire des bactéries. Cette découverte a jeté les bases de l'utilisation des antibiotiques dans le traitement des infections et a ouvert la porte à de futures avancées dans le domaine de la médecine.\"\n",
    "encoded = tokenizer.encode(test)\n",
    "print(len(test.split(\" \")))\n",
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZephyrLLM(CustomLLM):\n",
    "    context_window: int = 2048\n",
    "    num_output: int = 256\n",
    "    model_name: str = \"custom\"\n",
    "    dummy_response: str = \"My response\"\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=context_window,\n",
    "            num_output=num_output,\n",
    "            model_name=model_name\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        prompt_length = len(prompt)\n",
    "        response = pipeline(prompt, max_new_tokens=num_output)[0][\"generated_text\"]\n",
    "\n",
    "        # only return newly generated tokens\n",
    "        text = response[prompt_length:]\n",
    "        return CompletionResponse(text=text)\n",
    "    \n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(self, prompt: str, **kwargs: Any) -> CompletionResponseGen:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1c9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FalconLLM(CustomLLM):\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=context_window,\n",
    "            num_output=num_output,\n",
    "            model_name=model_name\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        prompt_length = len(prompt)\n",
    "        response = pipeline(prompt, max_new_tokens=num_output)[0][\"generated_text\"]\n",
    "\n",
    "        # only return newly generated tokens\n",
    "        text = response[prompt_length:]\n",
    "        return CompletionResponse(text=text)\n",
    "    \n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(self, prompt: str, **kwargs: Any) -> CompletionResponseGen:\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e70871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/xli/.cache/torch/sentence_transformers/dangvantuan_sentence-camembert-large. Creating a new one with MEAN pooling.\n",
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "context_window = 2048\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "chunk_size = 512\n",
    "\n",
    "# define our LLM\n",
    "llm = FalconLLM()\n",
    "\n",
    "embed_model = HuggingFaceBgeEmbeddings(model_name=\"dangvantuan/sentence-camembert-large\")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    embed_model=embed_model,\n",
    "    context_window=context_window, \n",
    "    chunk_size=chunk_size,\n",
    "    num_output=num_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd49cf",
   "metadata": {},
   "source": [
    "### Create nebula space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0b8516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Pool Created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digital_safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rag_workshop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name\n",
       "0  digital_safety\n",
       "1    rag_workshop"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext ngql\n",
    "connection_string = f\"--address 127.0.0.1 --port 9669 --user root --password nebula\"\n",
    "%ngql {connection_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abc26d",
   "metadata": {},
   "source": [
    "rag_workshop (index used for demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ngql\n",
    "CREATE SPACE IF NOT EXISTS rag_workshop(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);\n",
    "USE rag_workshop;\n",
    "CREATE TAG IF NOT EXISTS entity(name string);\n",
    "CREATE EDGE IF NOT EXISTS relationship(relationship string);\n",
    "CREATE TAG INDEX IF NOT EXISTS entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b206fe",
   "metadata": {},
   "source": [
    "digital_safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5973a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "CREATE SPACE IF NOT EXISTS digital_safety(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);\n",
    "USE digital_safety;\n",
    "CREATE TAG IF NOT EXISTS entity(name string);\n",
    "CREATE EDGE IF NOT EXISTS relationship(relationship string);\n",
    "CREATE TAG INDEX IF NOT EXISTS entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700edb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEBULA_USER'] = \"root\"\n",
    "os.environ['NEBULA_PASSWORD'] = \"nebula\"\n",
    "os.environ['NEBULA_ADDRESS'] = \"127.0.0.1:9669\"\n",
    "\n",
    "space_name = \"digital_safety\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\"relationship\"]\n",
    "tags = [\"entity\"]\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde8220",
   "metadata": {},
   "source": [
    "## Generate KG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e790f99",
   "metadata": {},
   "source": [
    "### Falcon 7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516dee10",
   "metadata": {},
   "source": [
    "### Mistral 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602259bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion(messages):\n",
    "    prompt = \"\"\n",
    "    for m in messages:\n",
    "        if m[\"role\"]==\"user\":\n",
    "            prompt += \"[INST]\" +  m[\"content\"] + \"[/INST]\"\n",
    "        elif m[\"role\"]==\"assistant\":\n",
    "            prompt += \"<s>\" + m[\"content\"] + \"</s>\"\n",
    "    \n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3132ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "You're an NLP expert, your task is to extract the triplets (subject, predicate, object) presented in given sentences.\n",
      "Here is an example:\n",
      "Text: She loves ice cream.\n",
      "Subject: She\n",
      "Predicate: loves\n",
      "Object: ice cream\n",
      "Here is another example:\n",
      "Text: Despite his initial reluctance, John successfully completed the challenging project.\n",
      "Subject: John\n",
      "Predicate: completed\n",
      "Object: challenging project\n",
      "</s>[INST]What is the subject, predicate and object in this sentence: The company's CEO, who is known for his innovative ideas, announced a groundbreaking partnership with a global tech giant. ?[/INST]\n"
     ]
    }
   ],
   "source": [
    "test = \"The company's CEO, who is known for his innovative ideas, announced a groundbreaking partnership with a global tech giant.\"\n",
    "assistant_message = \"\"\"\n",
    "You're an NLP expert, your task is to extract the triplets (subject, predicate, object) presented in given sentences.\n",
    "Here is an example:\n",
    "Text: She loves ice cream.\n",
    "Subject: She\n",
    "Predicate: loves\n",
    "Object: ice cream\n",
    "Here is another example:\n",
    "Text: Despite his initial reluctance, John successfully completed the challenging project.\n",
    "Subject: John\n",
    "Predicate: completed\n",
    "Object: challenging project\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"assistant\", \"content\": assistant_message},\n",
    "    {\"role\": \"user\", \"content\": f\"What is the subject, predicate and object in this sentence: {test} ?\"}\n",
    "]\n",
    "completed_prompt = chat_completion(messages)\n",
    "print(completed_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401168f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MistralKGIndex(KnowledgeGraphIndex):\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_triplet_response(\n",
    "        response: str, max_length: int = 128\n",
    "    ) -> List[Tuple[str, str, str]]:\n",
    "        knowledge_strs = response.strip().split(\"\\n\")\n",
    "        results = []\n",
    "        for text in knowledge_strs:\n",
    "            if not text or text[0] != \"(\" or text[-1] != \")\":\n",
    "                # skip empty lines and non-triplets\n",
    "                continue\n",
    "            tokens = text[1:-1].split(\",\")\n",
    "            if len(tokens) != 3:\n",
    "                continue\n",
    "\n",
    "            if any(len(s.encode(\"utf-8\")) > max_length for s in tokens):\n",
    "                # We count byte-length instead of len() for UTF-8 chars,\n",
    "                # will skip if any of the tokens are too long.\n",
    "                # This is normally due to a poorly formatted triplet\n",
    "                # extraction, in more serious KG building cases\n",
    "                # we'll need NLP models to better extract triplets.\n",
    "                continue\n",
    "\n",
    "            subj, pred, obj = map(str.strip, tokens)\n",
    "            if not subj or not pred or not obj:\n",
    "                # skip partial triplets\n",
    "                continue\n",
    "            results.append((subj, pred, obj))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36e8b634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/miniconda3/envs/llm_venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", Bob)\n",
      "---------------------\n",
      "Text: page_label: 13\n",
      "file_name: UP1-RS-SUR\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "visited over 100 cities in China.\"\n",
      "Triplets:\n",
      "(Beijing, Olympic, torch)\n",
      "(torch, Olympic, Beijing)\n",
      "(Olympic, torch, Beijing)\n",
      "---------------------\n",
      "Text: \"The 2008 Beijing Olympic Torch Relay was held on 8 July 2008. It began at the Great Wall\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", is, a)\n",
      "(The, is, a)\n",
      "(The, is, a)\n",
      "(The, is, a)\n",
      "(The, is, a)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a)\n",
      "(the, a, is)\n",
      "(the, is,\n",
      "\n",
      "---------\n",
      "Text: <noinput>\n",
      "Triplets:\n",
      "(Alice, is, mother of)\n",
      "(Bob, is, father of)\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", battery, cold)\n",
      "(Regulation, on, battery, cold)\n",
      "(Regulation, on, battery, cold)\n",
      "(Regulation, on, battery, cold)\n",
      "(Regulation, on, battery, cold)\n",
      "(Regulation, on, battery, cold)\n",
      "(Regulation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ur, caractéristiques, sont)\n",
      "(Leur, caractéristiques, sont)\n",
      "(Leur, caractéristiques, sont)\n",
      "(Leur, caractéristiques, sont)\n",
      "(Leur, caractéristiques\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lice\n",
      "put>\n",
      "Triplets:\n",
      "(Alice, is, mother)\n",
      "\n",
      "\n",
      "New York Stock Exchange, is, world's)\n",
      "(is, world's, largest)\n",
      "(world's, largest, is)\n",
      "---------------------\n",
      "Text: \"The <em>New York Stock Exchange</em> is the world's\n",
      "t: <noinput>\n",
      "Triplets:\n",
      "(Alice, is, Bob)\n",
      "(Bob, is, Alice)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "noinput>\n",
      "Triplets:\n",
      "(is, a, coffee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ext: <noinput>\n",
      "Triplets:\n",
      "(Alice, is, Bob)\n",
      "(Bob, is,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k, stock, exchange)\n",
      "(stock, exchange, new york)\n",
      "(exchange, new york, stock)\n",
      "---------------------\n",
      "Text: \"The <em>New York Stock Exchange</em> is the world's largest stock exchange.\"Triplets:\n",
      "(new york, stock, exchange)\n",
      "(stock,\n",
      "\n",
      "xt contains 2 triplets:\n",
      "(The, is, a)\n",
      "(The, is, a)\n",
      "---------------------\n",
      "Text: \n",
      "The following text contains 2 triplets\n",
      "elay)\n",
      "(Great Wall of China, torch relay)\n",
      "---------------------\n",
      "Text: \"The 2008 Beijing Olympic Torch Relay was held on 8 August 2008. It began at Tiananmen Square and ended at the Great Wall of China.\"\n",
      "Triplets:\n",
      "(torch relay, 2008, Beijing)\n",
      "------------\n",
      "Text: <noinput>\n",
      "Triplets\n",
      ": <noinput>\n",
      "Triplets:\n",
      "(is, a, subject)\n",
      "(is, a, predicate)\n",
      "(is, a, object\n",
      "\n",
      "\n",
      "d in, 2022)\n",
      "(Philz, founded in, 202\n",
      "\n",
      "ins 10 triplets:\n",
      "(\n",
      "dge triplett:\n",
      "(The, is, a)\n",
      "Triplets:\n",
      "(The, is, a)\n",
      "(The, is, a)\n",
      "(The, is, a)\n",
      "\n",
      "\n",
      "s, Alice's)\n",
      "(Alice, is, Bob's)\n",
      "---------------------\n",
      "bject)\n",
      "---------------------\n",
      "Text: <noinput>\n",
      "Triplets:\n",
      "(is, a, subject)\n",
      "(is,\n",
      "\n",
      "\n",
      "Bob)\n",
      "---------------------\n",
      "Text: <noinput>\n",
      "Triplets:\n",
      "(Alice, is, Bob)\n",
      "(Bob,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f, ventilators)\n",
      "(installations, of, ventilators)\n",
      "(installations, of, ventilators)\n",
      "(installations, of,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "xtract knowledge triples.\n",
      "---------------------\n",
      "Text: \n",
      "The following text\n",
      "\n",
      " coffee shop founded in 1982.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kg_index = MistralKGIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    kg_triple_extract_template=prompt,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b1f0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index.storage_context.persist(persist_dir='/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data/fr_embed_storage_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853beb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9025a7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"stock\")-[:relationship@-1179187948981095342{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"new york\")-[:relationship@219232360648163354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"is\")-[:relationship@-8433750674388488407{rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"is\")-[:relationship@-7462421433918528579{rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"is\")-[:relationship@-7462421433918528579{rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(\"the\")-[:relationship@-7462421433918528579{re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(\"installations\")-[:relationship@4754892476402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(\"exchange\")-[:relationship@392570128547222489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(\"torch relay\")-[:relationship@346655847438871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(\"The\")-[:relationship@-7810131783760243813{re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(\"torch\")-[:relationship@6308937301339263828{r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(\"Olympic\")-[:relationship@-893872262750489202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(\"Leur\")-[:relationship@3746971088232297599{re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(\"Bob\")-[:relationship@-7810131783760243813{re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(\"Bob\")-[:relationship@-7810131783760243813{re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(\"Beijing\")-[:relationship@6308937301339263828...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(\"world's\")-[:relationship@-310513206409421683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(\"Alice\")-[:relationship@-7810131783760243813{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(\"Alice\")-[:relationship@-7810131783760243813{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(\"Alice\")-[:relationship@-7810131783760243813{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(\"Alice\")-[:relationship@-7810131783760243813{...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    e\n",
       "0   (\"stock\")-[:relationship@-1179187948981095342{...\n",
       "1   (\"new york\")-[:relationship@219232360648163354...\n",
       "2   (\"is\")-[:relationship@-8433750674388488407{rel...\n",
       "3   (\"is\")-[:relationship@-7462421433918528579{rel...\n",
       "4   (\"is\")-[:relationship@-7462421433918528579{rel...\n",
       "5   (\"the\")-[:relationship@-7462421433918528579{re...\n",
       "6   (\"installations\")-[:relationship@4754892476402...\n",
       "7   (\"exchange\")-[:relationship@392570128547222489...\n",
       "8   (\"torch relay\")-[:relationship@346655847438871...\n",
       "9   (\"The\")-[:relationship@-7810131783760243813{re...\n",
       "10  (\"torch\")-[:relationship@6308937301339263828{r...\n",
       "11  (\"Olympic\")-[:relationship@-893872262750489202...\n",
       "12  (\"Leur\")-[:relationship@3746971088232297599{re...\n",
       "13  (\"Bob\")-[:relationship@-7810131783760243813{re...\n",
       "14  (\"Bob\")-[:relationship@-7810131783760243813{re...\n",
       "15  (\"Beijing\")-[:relationship@6308937301339263828...\n",
       "16  (\"world's\")-[:relationship@-310513206409421683...\n",
       "17  (\"Alice\")-[:relationship@-7810131783760243813{...\n",
       "18  (\"Alice\")-[:relationship@-7810131783760243813{...\n",
       "19  (\"Alice\")-[:relationship@-7810131783760243813{...\n",
       "20  (\"Alice\")-[:relationship@-7810131783760243813{..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql USE digital_safety;\n",
    "%ngql MATCH ()-[e]->() RETURN e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97f4493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f734a73b910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<class 'pyvis.network.Network'> |N|=25 |E|=21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3a2cc",
   "metadata": {},
   "source": [
    "## Load previously generated KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e9ac35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir='/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data/fr_embed_storage_graph', graph_store=graph_store)\n",
    "kg_index = load_index_from_storage(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dbdb0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"évents\")-[:relationship@-3431488967660501439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"zone_de_surpression\")-[:relationship@-738609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"zone_de_surpression\")-[:relationship@-738609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"zone_de_surpression\")-[:relationship@-738609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"zone_de_surpression\")-[:relationship@-738609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>(\"fumées\")-[:relationship@-3640410747914980111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>(\"fonctionnement normal\")-[:relationship@-7396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>(\"Implantation\")-[:relationship@65928469527764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>(\"Implantation\")-[:relationship@65928469527764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>(\"Implantation\")-[:relationship@65928469527764...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     e\n",
       "0    (\"évents\")-[:relationship@-3431488967660501439...\n",
       "1    (\"zone_de_surpression\")-[:relationship@-738609...\n",
       "2    (\"zone_de_surpression\")-[:relationship@-738609...\n",
       "3    (\"zone_de_surpression\")-[:relationship@-738609...\n",
       "4    (\"zone_de_surpression\")-[:relationship@-738609...\n",
       "..                                                 ...\n",
       "972  (\"fumées\")-[:relationship@-3640410747914980111...\n",
       "973  (\"fonctionnement normal\")-[:relationship@-7396...\n",
       "974  (\"Implantation\")-[:relationship@65928469527764...\n",
       "975  (\"Implantation\")-[:relationship@65928469527764...\n",
       "976  (\"Implantation\")-[:relationship@65928469527764...\n",
       "\n",
       "[977 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql USE rag_workshop;\n",
    "%ngql MATCH ()-[e]->() RETURN e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7913cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"nebulagraph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8c8bb2eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<class 'pyvis.network.Network'> |N|=898 |E|=977"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dab7bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.graph_stores.nebulagraph.NebulaGraphStore at 0x7f983175d7e0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_index.graph_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9c334ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP1\n",
      "usine\n",
      "objet\n",
      "champ d’application\n",
      "Usine\n",
      "Marcoule\n",
      "Usine UP1\n",
      "Usine Marcoule\n",
      "Philz\n",
      "1982\n",
      "Berkeley\n",
      "coffee shop\n",
      "PT\n",
      "générale\n",
      "risque\n",
      "opération\n",
      "atelier\n",
      "section\n",
      "libellé\n",
      "Plutonium\n",
      "limit\n",
      "criticité\n",
      "sûreté\n",
      "H\n",
      "PT spécifique\n",
      "I\n",
      "J\n",
      "K\n",
      "L\n",
      "M\n",
      "N\n",
      "O\n",
      "P\n",
      "L.1\n",
      "L.3\n",
      "L.4\n",
      "L.6\n",
      "L.8\n",
      "L.10\n",
      "L.12\n",
      "L.14\n",
      "L.16\n",
      "L.18\n",
      "L.20\n",
      "L.22\n",
      "L.24\n",
      "L.26\n",
      "L.28\n",
      "L.30\n",
      "L.32\n",
      "L.34\n",
      "L.36\n",
      "P.1\n",
      "P.3\n",
      "effluents\n",
      "solutions actives\n",
      "assainissement\n",
      "masse\n",
      "soluble\n",
      "cumul\n",
      "inférieure\n",
      "bat 117\n",
      "traitement\n",
      "text: Philz\n",
      "RDS\n",
      "R0\n",
      "Page\n",
      "10\n",
      "/ 10\n",
      "013413\n",
      "9\n",
      "32\n",
      "1\n",
      "boîte à gants\n",
      "procédé\n",
      "démantelée\n",
      "MAR 09 013413\n",
      "site\n",
      "bâtiment 100\n",
      "bâtiment 117\n",
      "température\n",
      "température minimale\n",
      "température maximale\n",
      "température moyenne\n",
      "température moyenne des mois d’hiver\n",
      "température moyenne des mois d’été\n",
      "température de 30°C\n",
      "nombre de jours de gelée sous abri\n",
      "humidité de l’air\n",
      "précipitation\n",
      "vent dominant\n",
      "vitesse moyenne des vents\n",
      "mistral de l’ordre de 70 à 80 km/h\n",
      "barrière dynamique\n",
      "vitesse de passage\n",
      "barrière statique\n",
      "taux de renouvellement\n",
      "page_label\n",
      "2\n",
      "ventilation\n",
      "e\n",
      "t\n",
      "l\n",
      "o\n",
      ",\n",
      "<\n",
      "[\n",
      "s\n",
      "-\n",
      " \n",
      "n\n",
      "a\n",
      "i\n",
      "m\n",
      "]\n",
      "g\n",
      "f\n",
      ">\n",
      "û\n",
      "é\n",
      "r\n",
      "u\n",
      "q\n",
      "d\n",
      "p\n",
      "c\n",
      ".\n",
      "6\n",
      "b\n",
      "’\n",
      "F\n",
      "4\n",
      "D\n",
      "A\n",
      "0\n",
      "3\n",
      "S\n",
      "R\n",
      "k\n",
      "E\n",
      "7\n",
      "B\n",
      "à\n",
      "h\n",
      "T\n",
      "8\n",
      "5\n",
      "v\n",
      "y\n",
      "'\n",
      "z\n",
      "_\n",
      "j\n",
      "U\n",
      "x\n",
      ":\n",
      "/\n",
      "C\n",
      "è\n",
      "â\n",
      "V\n",
      "°\n",
      "î\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "g = kg_index.get_networkx_graph()\n",
    "for n in g.nodes:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7505377",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index_query_engine = kg_index.as_query_engine(\n",
    "    retriever_mode=\"keyword\",\n",
    "    verbose=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "response_graph_rag = kg_index_query_engine.query(\"Résume moi\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_graph_rag}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_graph_rag = kg_index_query_engine.query(\"Résume moi\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_graph_rag}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = ListIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "# Query and print response\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Quel est le titre du chapitre 5 ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save_to_disk(\"/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.index_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c62b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(\"/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data/index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059214a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data/index\")\n",
    "index = ListIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "new_index = load_index_from_storage(storage_context, service_context=service_context)\n",
    "new_query_engine = new_index.as_query_engine()\n",
    "response = new_query_engine.query(\"Quel est le titre du chapitre 5 ?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
