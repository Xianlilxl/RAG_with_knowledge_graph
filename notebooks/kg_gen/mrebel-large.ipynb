{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1661a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import math\n",
    "import torch\n",
    "import IPython\n",
    "from typing import Dict\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09936a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the generated text and extract the triplets\n",
    "def extract_triplets_typed(text):\n",
    "    triplets = []\n",
    "    relation = ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    subject, relation, object_, object_type, subject_type = '','','','',''\n",
    "    \n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").replace(\"tp_XX\", \"\").replace(\"__en__\", \"\").split():\n",
    "        if token == \"<triplet>\" or token == \"<relation>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({\n",
    "                        'Subject': subject.strip(), \n",
    "                        # 'head_type': subject_type, \n",
    "                        'Predicate': relation.strip(),\n",
    "                        'Object': object_.strip(), \n",
    "                        # 'tail_type': object_type\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token.startswith(\"<\") and token.endswith(\">\"):\n",
    "            if current == 't' or current == 'o':\n",
    "                current = 's'\n",
    "                if relation != '':\n",
    "                    triplets.append({\n",
    "                        'Subject': subject.strip(), \n",
    "                        'head_type': subject_type, \n",
    "                        'Predicate': relation.strip(),\n",
    "                        'Object': object_.strip(), \n",
    "                        'tail_type': object_type\n",
    "                    })\n",
    "                object_ = ''\n",
    "                subject_type = token[1:-1]\n",
    "            else:\n",
    "                current = 'o'\n",
    "                object_type = token[1:-1]\n",
    "                relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '' and object_type != '' and subject_type != '':\n",
    "        triplets.append({\n",
    "            'Subject': subject.strip(), \n",
    "            # 'head_type': subject_type, \n",
    "            'Predicate': relation.strip(),\n",
    "            'Object': object_.strip(), \n",
    "            # 'tail_type': object_type\n",
    "        })\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(example: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and structures relations from a single example within a English dataset.\n",
    "\n",
    "    Args:\n",
    "        example (dict): A dictionary containing entities and relations.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the extracted relations.\n",
    "\n",
    "    Example:\n",
    "        Given an 'example' dictionary containing 'entities' and 'relations', this function\n",
    "        extracts and structures relations, returning them as a string.\n",
    "\n",
    "    \"\"\"\n",
    "    entities_ls = example[\"entities\"]\n",
    "    relations = []\n",
    "    for relation in example[\"relations\"]:\n",
    "        relation_dict = {}\n",
    "        object_index = relation[\"object\"]\n",
    "        relation_dict[\"Object\"] = entities_ls[object_index][\"surfaceform\"]\n",
    "        relation_dict[\"Predicate\"] = relation[\"predicate\"]\n",
    "        subject_index = relation[\"subject\"]\n",
    "        relation_dict[\"Subject\"] = entities_ls[subject_index][\"surfaceform\"]\n",
    "        relations.append(relation_dict)\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(test_example):\n",
    "    try:\n",
    "        prompt, _ = tuple(test_example[\"text\"].split(\"### ENTITES:\"))\n",
    "    except:\n",
    "        prompt, _ = tuple(test_example[\"text\"].split(\"### ENTITIES:\"))\n",
    "    prompt+=\"### RELATIONS:\\n\"\n",
    "    test_example[\"prompt\"] = prompt\n",
    "    test_example[\"ground_truth\"]=get_relation(test_example)\n",
    "    return test_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_positive(test_example):\n",
    "    gt_ls = test_example[\"ground_truth\"]\n",
    "    pred_ls = test_example[\"prediction_dict\"]\n",
    "    true_positive = 0\n",
    "    for pred in pred_ls:\n",
    "        if pred in gt_ls:\n",
    "            true_positive+=1 \n",
    "    test_example[\"correct\"] = true_positive\n",
    "    test_example[\"guess\"] = len(test_example[\"ground_truth\"])\n",
    "    test_example[\"gold\"] = len(test_example[\"prediction_dict\"])\n",
    "    return test_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549acaf8",
   "metadata": {},
   "source": [
    "# Test with code from model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "triplet_extractor = pipeline(\n",
    "    'translation_xx_to_yy', \n",
    "    model='Babelscape/mrebel-large', \n",
    "    tokenizer='Babelscape/mrebel-large', \n",
    "    device_map=\"auto\"\n",
    "    # device=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Subject': 'Albert Einstein', 'Predicate': 'notable work', 'Object': 'théorie de la relativité'}, {'Subject': 'théorie de la relativité', 'Predicate': 'discoverer or inventor', 'Object': 'Albert Einstein'}]\n",
      "[{'Subject': 'tour Eiffel', 'Predicate': 'located in the administrative territorial entity', 'Object': 'Paris'}]\n",
      "[{'Subject': 'Steve Jobs', 'Predicate': 'employer', 'Object': 'Apple Inc.'}, {'Subject': 'Apple Inc.', 'Predicate': 'founded by', 'Object': 'Steve Jobs'}]\n",
      "[{'Subject': '100 degrés Celsius', 'Predicate': 'duration', 'Object': '100'}]\n",
      "[{'Subject': 'évolution', 'Predicate': 'discoverer or inventor', 'Object': 'Charles Darwin'}, {'Subject': 'Charles Darwin', 'Predicate': 'field of work', 'Object': 'biologie'}]\n",
      "[{'Subject': 'singularité gravitationnelle', 'Predicate': 'part of', 'Object': 'trous noirs'}]\n",
      "[{'Subject': 'neurosciences', 'Predicate': 'studies', 'Object': 'cerveau'}]\n",
      "[{'Subject': 'clonage humain', 'Predicate': 'subclass of', 'Object': 'manipulation génétique'}]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Albert Einstein a développé la théorie de la relativité.\",\n",
    "    \"La tour Eiffel se trouve à Paris.\", \n",
    "    \"Steve Jobs a cofondé Apple Inc.\", \n",
    "    \"L'eau bout à 100 degrés Celsius.\",\n",
    "    \"Malgré les controverses, la théorie de l'évolution, élaborée par Charles Darwin au XIXe siècle, demeure le fondement de la biologie moderne.\", \n",
    "    \"La singularité gravitationnelle au cœur des trous noirs, où la densité atteint l'infini, défie notre compréhension actuelle de la physique théorique.\",\n",
    "    \"La neuroplasticité, un concept révolutionnaire dans les neurosciences, suggère que le cerveau peut se remodeler et s'adapter tout au long de la vie.\",\n",
    "    \"Les enjeux éthiques entourant la manipulation génétique et le clonage humain exigent une réflexion approfondie de la part de la société contemporaine.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    extracted_text = triplet_extractor.tokenizer.batch_decode(\n",
    "        [triplet_extractor(\n",
    "            sentence, \n",
    "            decoder_start_token_id=250058, \n",
    "            src_lang=\"fr_XX\", \n",
    "            tgt_lang=\"<triplet>\", \n",
    "            return_tensors=True, \n",
    "            return_text=False\n",
    "        )[0][\"translation_token_ids\"]]\n",
    "    )\n",
    "    extracted_triplets = extract_triplets_typed(extracted_text[0])\n",
    "    print(extracted_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86f03308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp_XX<triplet> Opel GTC Concept <misc> concept car <misc> instance of <misc> Opel <concept> manufacturer</s>\n",
      "[{'Subject': 'Opel GTC Concept', 'head_type': 'misc', 'Predicate': 'instance of', 'Object': 'concept car', 'tail_type': 'misc'}, {'Subject': 'Opel GTC Concept', 'Predicate': 'manufacturer', 'Object': 'Opel'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We need to use the tokenizer manually since we need special tokens.\n",
    "# sentence = \"Malgré son manque d'expérience, le jeune artiste a peint un tableau extraordinaire qui a ébloui les critiques d'art les plus sévères.\"\n",
    "# sentence = \"The introduction of co-feedstocks increased the CH4 production\"\n",
    "sentence = \"L'Opel GTC Concept, abrégé \\\"Opel Gran Turismo Coupé Concept\\\", est un concept car produit par Opel depuis 2007. Il a été dévoilé au Salon de Genève.\"\n",
    "# sentence = \"The cat eats the mouse.\"\n",
    "extracted_text = triplet_extractor.tokenizer.batch_decode(\n",
    "    [triplet_extractor(\n",
    "        sentence, \n",
    "        decoder_start_token_id=250058, \n",
    "        src_lang=\"fr_XX\", \n",
    "        tgt_lang=\"<triplet>\", \n",
    "        return_tensors=True, \n",
    "        return_text=False\n",
    "    )[0][\"translation_token_ids\"]]\n",
    ") # change en_XX for the language of the source.\n",
    "print(extracted_text[0])\n",
    "\n",
    "extracted_triplets = extract_triplets_typed(extracted_text[0])\n",
    "print(extracted_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(test_example):\n",
    "    try:\n",
    "        sentence = test_example[\"text\"].split(\"### TEXTE:\")[1].split(\"\\n\\n\")[0]\n",
    "    except:\n",
    "        sentence = test_example[\"text\"].split(\"### TEXT:\")[1].split(\"\\n\\n\")[0]\n",
    "    extracted_text = triplet_extractor.tokenizer.batch_decode(\n",
    "        [triplet_extractor(\n",
    "            sentence, \n",
    "            decoder_start_token_id=250058, \n",
    "            src_lang=\"fr_XX\", \n",
    "            tgt_lang=\"<triplet>\", \n",
    "            return_tensors=True, \n",
    "            return_text=False\n",
    "        )[0][\"translation_token_ids\"]]\n",
    "    ) # change en_XX for the language of the source.\n",
    "    # print(extracted_text[0])\n",
    "    triplets = extract_triplets_typed(extracted_text[0])\n",
    "    # print(triplets)\n",
    "    test_example[\"prediction_dict\"] = triplets\n",
    "    return test_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004ded53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['docid', 'title', 'uri', 'text', 'entities', 'relations', 'prompt', 'ground_truth'],\n",
       "    num_rows: 2525\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"/home/xli/Documents/Digital safety/src/notebooks/finetune/datasets/bright-shape-68/SREDFM-dataset:v5/test/\"\n",
    "test_dataset = load_from_disk(dataset_path)\n",
    "GT_test_dataset = test_dataset.map(get_ground_truth)\n",
    "GT_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a028c8ed958a4cba8b6d1275c0ff4c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['docid', 'title', 'uri', 'text', 'entities', 'relations', 'prompt', 'ground_truth', 'prediction_dict'],\n",
       "    num_rows: 2525\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_pred_dataset = GT_test_dataset.map(get_prediction)\n",
    "GT_pred_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411e6d1ddd7845cbb8da0f4e3e846f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313941188914745 0.6137747930657504 0.706199460916442\n"
     ]
    }
   ],
   "source": [
    "metrics_dataset = GT_pred_dataset.map(get_true_positive)\n",
    "\n",
    "correct = sum(metrics_dataset[\"correct\"])\n",
    "guess = sum(metrics_dataset[\"guess\"])\n",
    "gold = sum(metrics_dataset[\"gold\"])\n",
    "\n",
    "precision = float(correct)/float(guess)\n",
    "recall = float(correct)/float(gold)\n",
    "f1_score = 2*precision*recall/(precision+recall)\n",
    "print(precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vous êtes un expert en data science et en traitement du langage naturel(NLP).\n",
      "Votre tâche consiste à extraire les triplets du TEXTE fourni ci-dessous.\n",
      "Les entité s'agit du sujet et de l'objet d'une phrase, la liste d'entités doit être sous forme:\n",
      "['entité1', 'entité2', 'entité3', ...]\n",
      "Un triplet de connaissances est constitué de 2 entités (sujet et objet) liées par un prédicat : \n",
      "{\"Objet\": \"\",\"Prédicat\": \"\", \"Sujet\": \"\" }\n",
      "Les triples multiples doivent être sous forme de liste.\n",
      "\n",
      "### TEXTE:\n",
      "L'Opel GTC Concept, abrégé \"Opel Gran Turismo Coupé Concept\", est un concept car produit par Opel depuis 2007. Il a été dévoilé au Salon de Genève.\n",
      "\n",
      "### ENTITES:\n",
      "[\"Opel GTC Concept\", \"Salon de Genève\", \"Opel\", \"2007\", \"concept car\"]\n",
      "\n",
      "### RELATIONS:\n",
      "[{\"Object\": \"concept car\", \"Predicate\": \"instance of\", \"Subject\": \"Opel GTC Concept\"}, {\"Object\": \"Opel\", \"Predicate\": \"manufacturer\", \"Subject\": \"Opel GTC Concept\"}]</s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(GT_test_dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "pred = get_prediction(GT_test_dataset[0])[\"prediction_dict\"]\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] in GT_test_dataset[0][\"ground_truth\"]:\n",
    "        print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set English (\"en_XX\") as source language. To change the source language swap the first token of the input for your desired language or change to supported language. For catalan (\"ca_XX\") or greek (\"el_EL\") (not included in mBART pretraining) you need a workaround:\n",
    "# tokenizer._src_lang = \"ca_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/mrebel-large\", src_lang=\"fr_XX\", tgt_lang=\"tp_XX\") \n",
    "# Here we set English (\"en_XX\") as source language. To change the source language swap the first token of the input for your desired language or change to supported language. For catalan (\"ca_XX\") or greek (\"el_EL\") (not included in mBART pretraining) you need a workaround:\n",
    "# tokenizer._src_lang = \"ca_XX\"\n",
    "# tokenizer.cur_lang_code_id = tokenizer.convert_tokens_to_ids(\"ca_XX\")\n",
    "# tokenizer.set_src_lang_special_tokens(\"ca_XX\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/mrebel-large\")\n",
    "\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 3,\n",
    "    \"num_return_sequences\": 3,\n",
    "    \"forced_bos_token_id\": None,\n",
    "}\n",
    "\n",
    "# Text to extract triplets from\n",
    "# text = 'Le chat mange la souris.'\n",
    "text = \"le chercheur renommé a présenté sa recherche novatrice sur l'apprentissage automatique\"\n",
    "\n",
    "# Tokenizer text\n",
    "model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt').to(device)\n",
    "\n",
    "# Generate\n",
    "model = model.to(device)\n",
    "generated_tokens = model.generate(\n",
    "    model_inputs[\"input_ids\"].to(model.device),\n",
    "    attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "    decoder_start_token_id = tokenizer.convert_tokens_to_ids(\"tp_XX\"),\n",
    "    **gen_kwargs,\n",
    ")\n",
    "\n",
    "# Extract text\n",
    "decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "# Extract triplets\n",
    "for idx, sentence in enumerate(decoded_preds):\n",
    "    print(f'Prediction triplets sentence {idx}')\n",
    "    print(extract_triplets_typed(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de14d8",
   "metadata": {},
   "source": [
    "# Test with medium post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations_from_model_output(text):\n",
    "    relations = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        relations.append({\n",
    "            'head': subject.strip(),\n",
    "            'type': relation.strip(),\n",
    "            'tail': object_.strip()\n",
    "        })\n",
    "    return relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a7a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.relations = []\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "\n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "\n",
    "    def add_relation(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")\n",
    "            \n",
    "    def merge_relations(self, r1):\n",
    "        r2 = [r for r in self.relations\n",
    "              if self.are_relations_equal(r1, r)][0]\n",
    "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n",
    "                        if span not in r2[\"meta\"][\"spans\"]]\n",
    "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
    "\n",
    "    def add_relation(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "        else:\n",
    "            self.merge_relations(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_small_text_to_kb(text, verbose=False):\n",
    "    kb = KB()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/mrebel-large\", src_lang=\"fr_XX\", tgt_lang=\"tp_XX\") \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/mrebel-large\")\n",
    "\n",
    "#     device = \"cpu\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenizer text\n",
    "    model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt').to(device)\n",
    "\n",
    "    # Generate\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 256,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 3,\n",
    "        \"num_return_sequences\": 3,\n",
    "        \"forced_bos_token_id\": None,\n",
    "    }\n",
    "\n",
    "    model = model.to(device)\n",
    "    generated_tokens = model.generate(\n",
    "        model_inputs[\"input_ids\"].to(model.device),\n",
    "        attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "        decoder_start_token_id = tokenizer.convert_tokens_to_ids(\"tp_XX\"),\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "\n",
    "    # Extract text\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    for sentence_pred in decoded_preds:\n",
    "        print(sentence_pred)\n",
    "        relations = extract_triplets_typed(sentence_pred)\n",
    "        for r in relations:\n",
    "            kb.add_relation(r)\n",
    "\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73201cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_text_to_kb(text, span_length=128, verbose=False):\n",
    "    kb = KB()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/mrebel-large\", src_lang=\"fr_XX\", tgt_lang=\"tp_XX\") \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/mrebel-large\")\n",
    "\n",
    "#     device = \"cpu\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # tokenize whole text\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # compute span boundaries\n",
    "    num_tokens = len(inputs[\"input_ids\"][0])\n",
    "    if verbose:\n",
    "        print(f\"Input has {num_tokens} tokens\")\n",
    "    num_spans = math.ceil(num_tokens / span_length)\n",
    "    if verbose:\n",
    "        print(f\"Input has {num_spans} spans\")\n",
    "    overlap = math.ceil((num_spans * span_length - num_tokens) / \n",
    "                        max(num_spans - 1, 1))\n",
    "    spans_boundaries = []\n",
    "    start = 0\n",
    "    for i in range(num_spans):\n",
    "        spans_boundaries.append([start + span_length * i,\n",
    "                                 start + span_length * (i + 1)])\n",
    "        start -= overlap\n",
    "    if verbose:\n",
    "        print(f\"Span boundaries are {spans_boundaries}\")\n",
    "\n",
    "    # transform input with spans\n",
    "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
    "                  for boundary in spans_boundaries]\n",
    "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
    "                    for boundary in spans_boundaries]\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.stack(tensor_ids),\n",
    "        \"attention_mask\": torch.stack(tensor_masks)\n",
    "    }\n",
    "\n",
    "    # generate relations\n",
    "    num_return_sequences = 3\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 256,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 3,\n",
    "        \"num_return_sequences\": num_return_sequences\n",
    "    }\n",
    "    model = model.to(device)\n",
    "    generated_tokens = model.generate(\n",
    "        decoder_start_token_id = tokenizer.convert_tokens_to_ids(\"tp_XX\"),\n",
    "        **inputs,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "\n",
    "    # decode relations\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
    "                                           skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    kb = KB()\n",
    "    i = 0\n",
    "    for sentence_pred in decoded_preds:\n",
    "        current_span_index = i // num_return_sequences\n",
    "        relations = extract_triplets_typed(sentence_pred)\n",
    "        print(relations)\n",
    "        for relation in relations:\n",
    "            relation[\"meta\"] = {\n",
    "                \"spans\": [spans_boundaries[current_span_index]]\n",
    "            }\n",
    "            kb.add_relation(relation)\n",
    "        i += 1\n",
    "\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 \" \\\n",
    "\"May 1821), and later known by his regnal name Napoleon I, was a French military \" \\\n",
    "\"and political leader who rose to prominence during the French Revolution and led \" \\\n",
    "\"several successful campaigns during the Revolutionary Wars. He was the de facto \" \\\n",
    "\"leader of the French Republic as First Consul from 1799 to 1804. As Napoleon I, \" \\\n",
    "\"he was Emperor of the French from 1804 until 1814 and again in 1815. Napoleon's \" \\\n",
    "\"political and cultural legacy has endured, and he has been one of the most \" \\\n",
    "\"celebrated and controversial leaders in world history.\"\n",
    "\n",
    "kb = from_small_text_to_kb(text, verbose=True)\n",
    "kb.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 May 1821), and later known by his regnal name Napoleon I, was a French military and political leader who rose to prominence during the French Revolution and led several successful campaigns during the Revolutionary Wars. He was the de facto leader of the French Republic as First Consul from 1799 to 1804. As Napoleon I, he was Emperor of the French from 1804 until 1814 and again in 1815. Napoleon's political and cultural legacy has endured, and he has been one of the most celebrated and controversial leaders in world history. Napoleon was born on the island of Corsica not long after its annexation by the Kingdom of France.[5] He supported the French Revolution in 1789 while serving in the French army, and tried to spread its ideals to his native Corsica. He rose rapidly in the Army after he saved the governing French Directory by firing on royalist insurgents. In 1796, he began a military campaign against the Austrians and their Italian allies, scoring decisive victories and becoming a national hero. Two years later, he led a military expedition to Egypt that served as a springboard to political power. He engineered a coup in November 1799 and became First Consul of the Republic. Differences with the British meant that the French faced the War of the Third Coalition by 1805. Napoleon shattered this coalition with victories in the Ulm Campaign, and at the Battle of Austerlitz, which led to the dissolving of the Holy Roman Empire. In 1806, the Fourth Coalition took up arms against him because Prussia became worried about growing French influence on the continent. Napoleon knocked out Prussia at the battles of Jena and Auerstedt, marched the Grande Armée into Eastern Europe, annihilating the Russians in June 1807 at Friedland, and forcing the defeated nations of the Fourth Coalition to accept the Treaties of Tilsit. Two years later, the Austrians challenged the French again during the War of the Fifth Coalition, but Napoleon solidified his grip over Europe after triumphing at the Battle of Wagram. Hoping to extend the Continental System, his embargo against Britain, Napoleon invaded the Iberian Peninsula and declared his brother Joseph King of Spain in 1808. The Spanish and the Portuguese revolted in the Peninsular War, culminating in defeat for Napoleon's marshals. Napoleon launched an invasion of Russia in the summer of 1812. The resulting campaign witnessed the catastrophic retreat of Napoleon's Grande Armée. In 1813, Prussia and Austria joined Russian forces in a Sixth Coalition against France. A chaotic military campaign resulted in a large coalition army defeating Napoleon at the Battle of Leipzig in October 1813. The coalition invaded France and captured Paris, forcing Napoleon to abdicate in April 1814. He was exiled to the island of Elba, between Corsica and Italy. In France, the Bourbons were restored to power. However, Napoleon escaped Elba in February 1815 and took control of France.[6][7] The Allies responded by forming a Seventh Coalition, which defeated Napoleon at the Battle of Waterloo in June 1815. The British exiled him to the remote island of Saint Helena in the Atlantic, where he died in 1821 at the age of 51. Napoleon had an extensive impact on the modern world, bringing liberal reforms to the many countries he conquered, especially the Low Countries, Switzerland, and parts of modern Italy and Germany. He implemented liberal policies in France and Western Europe.\n",
    "\"\"\"\n",
    "\n",
    "kb = from_text_to_kb(text, verbose=True)\n",
    "kb.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc17e95",
   "metadata": {},
   "source": [
    "## Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59542d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pypdf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdfe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_path: Path):\n",
    "    with open(file_path, \"rb\") as fp:\n",
    "        # Create a PDF object\n",
    "        pdf = pypdf.PdfReader(fp)\n",
    "        # Get the number of pages in the PDF document\n",
    "        num_pages = len(pdf.pages)\n",
    "\n",
    "        # Iterate over every page\n",
    "        docs = []\n",
    "        for page in range(num_pages):\n",
    "            # Extract the text from the page\n",
    "            page_text = pdf.pages[page].extract_text()\n",
    "            if len(page_text)!=0:\n",
    "                page_label = pdf.page_labels[page]\n",
    "                metadata = {\"page_label\": page_label, \"file_name\": file_path.name}\n",
    "                docs.append({\"text\":page_text, \"metadata\":metadata})\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d92a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_filepaths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in glob.glob(root+\"/*.pdf\"):\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = Path(\"/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data/Données Digital Safety\")\n",
    "file_paths = get_pdf_filepaths(doc_path)\n",
    "text = []\n",
    "for file in file_paths:\n",
    "    docs = extract_text(Path(file))\n",
    "    if len(docs)!=0:\n",
    "        text = docs.copy()\n",
    "        break\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd14d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339683f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87161ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547cb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"L’exploitant veillera notamment à ce que le personnel affecté aux opérations de MAD/DEM et de RCD de l’usine UP1 possède les aptitudes professionnelles normalement requises, ait reçu une formation appropriée et dispose des habilitations et des moyens de surveillance (individuels ou collectifs) adaptés aux risques présentés par les opérations réalisées.\"\n",
    "# test = \"Le chat mange la souris\"\n",
    "test = f\"\"\"Malgré les défis économiques et politiques, l'entreprise a réussi à développer une technologie innovante qui pourrait transformer l'industrie.\"\"\"\n",
    "time_start=time.time()\n",
    "\n",
    "kb = from_small_text_to_kb(test, verbose=True)\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')\n",
    "kb.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "prompt = f\"\"\"\n",
    ">>CONTEXT<<\n",
    "Tu est un expert en NLP, tu as pour tâche d'extraire les triples (sujet, prédicat, objet) présenté dans des phrases données.\n",
    "Voici un exemple :\n",
    "Phrase : \"Le chien mange une croquette.\"\n",
    "Sujet : Le chien\n",
    "Prédicat : mange\n",
    "Objet : une croquette\n",
    "Voici un autre exemple plus compliqué : \n",
    "Phrase : \"le chercheur renommé a présenté sa recherche novatrice sur l'apprentissage automatique\"\n",
    "Sujet : Le chercheur\n",
    "Prédicat : a présenté\n",
    "Objet : sa recherche\n",
    ">>QUESTION<< Quel est le sujet, le prédicat, et l'objet dans cette phrase : {test} ?  \n",
    ">>ANSWER<<\n",
    "\"\"\"\n",
    "data = {\"prompt\": prompt, \"temperature\": 0.1}\n",
    "time_start=time.time()\n",
    "res = requests.post(\"http://127.0.0.1:8080/v1/models/model:predict\", json=data)\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')\n",
    "print(res.json()[\"data\"][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195dc885",
   "metadata": {},
   "source": [
    "## Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_reader = \"/mnt/c/Users/xli.ASSYSTEM/Documents/Digital safety/data/response_UP1-RG-SUR-0288_1_UP1_PT_VF.json\"\n",
    "\n",
    "with open(response_reader, 'r') as json_file:\n",
    "    response = json.load(json_file)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e413cc",
   "metadata": {},
   "source": [
    "## Test with REDFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from rebel.src.score import re_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75692916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_relation(example):\n",
    "    relations = []\n",
    "    for relation in example['relations']:\n",
    "        tail = (relation['object']['start'],relation['object']['end'])\n",
    "        head = (relation['subject']['start'],relation['subject']['end'])\n",
    "        predicate = RELATION_NAMES[relation['predicate']]\n",
    "        relations.append(\n",
    "            {\n",
    "                \"head\": (relation['subject']['start'],relation['subject']['end']),\n",
    "                \"tail\": (relation['object']['start'],relation['object']['end']),\n",
    "                \"head_type\": relation['subject']['type'],\n",
    "                \"tail_type\": relation['subject']['type'],\n",
    "                \"type\": RELATION_NAMES[relation['predicate']]\n",
    "            }\n",
    "        )\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_relation(text, tokenizer, model, verbose=False):\n",
    "#     device = \"cpu\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Tokenizer text\n",
    "    model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt').to(device)\n",
    "\n",
    "    # Generate\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 256,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 3,\n",
    "        \"num_return_sequences\": 3,\n",
    "        \"forced_bos_token_id\": None,\n",
    "    }\n",
    "\n",
    "    model = model.to(device)\n",
    "    generated_tokens = model.generate(\n",
    "        model_inputs[\"input_ids\"].to(model.device),\n",
    "        attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "        decoder_start_token_id = tokenizer.convert_tokens_to_ids(\"tp_XX\"),\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "\n",
    "    # Extract text\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    relations = []\n",
    "    for sentence_pred in decoded_preds:\n",
    "        print(sentence_pred)\n",
    "        relations.append(extract_triplets_typed(sentence_pred))\n",
    "    # Extract triplets\n",
    "    for idx, sentence in enumerate(decoded_preds):\n",
    "        print(f'Prediction triplets sentence {idx}')\n",
    "        re = extract_triplets_typed(sentence)\n",
    "#         print(len(re))\n",
    "#     relations = list(itertools.chain(*relations))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15853a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Babelscape/REDFM\", 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fe600",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/mrebel-large\", src_lang=\"fr_XX\", tgt_lang=\"tp_XX\") \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/mrebel-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71224a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2aae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_relation(dataset[\"validation\"][0][\"text\"], tokenizer, model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83831f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_relations = [convert_relation(example) for example in dataset[\"validation\"]]\n",
    "gold_relations = list(itertools.chain(*gold_relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4452cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[re[\"predicate\"] for re in dataset[\"validation\"][0][\"relations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98079422",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_relations = [from_small_text_to_kb(example[\"text\"]).relations for example in dataset[\"validation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1a7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a736c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"validation\"][0][\"relations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c77612",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATION_NAMES=['country', 'place of birth', 'spouse', 'country of citizenship', 'instance of',\n",
    "            'capital', 'child', 'shares border with', 'author', 'director', 'occupation',\n",
    "              'founded by', 'league', 'owned by', 'genre', 'named after', 'follows',\n",
    "                'headquarters location', 'cast member', 'manufacturer',\n",
    "                  'located in or next to body of water', 'location', 'part of', \n",
    "                  'mouth of the watercourse', 'member of', 'sport', 'characters',\n",
    "                    'participant', 'notable work', 'replaces', 'sibling', 'inception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(example):\n",
    "\n",
    "    relations = []\n",
    "    for relation in example['relations']:\n",
    "        object = relation['object']['surfaceform']\n",
    "        subject = relation['subject']['surfaceform']\n",
    "        predicate = RELATION_NAMES[relation['predicate']]\n",
    "        relations.append(f\"[’{subject}’, ’{predicate}’, ’{object}’]\")\n",
    "\n",
    " \n",
    "    return ' | '.join(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(example):\n",
    "\n",
    "    relations = []\n",
    "    for relation in example['entities']:\n",
    "        object = relation['object']['surfaceform']\n",
    "        subject = relation['subject']['surfaceform']\n",
    "        predicate = RELATION_NAMES[relation['predicate']]\n",
    "        relations.append(f\"[’{subject}’, ’{predicate}’, ’{object}’]\")\n",
    "\n",
    " \n",
    "    return ' | '.join(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[\"validation\"][0].copy()\n",
    "print(get_relation(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e669660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8da3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
